{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Structure for all Notebooks \n",
    "## 1) Describe the problem being tackled, source of data, output \n",
    "## 2) Import libraries/set up wd; general working setup\n",
    "## 3) Examine the quality of the data \n",
    "## 4) Build the right dataset \n",
    "## 5) Apply the structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T10:50:50.581497Z",
     "start_time": "2020-07-28T10:50:50.578821Z"
    }
   },
   "source": [
    "# Problem \n",
    "### What are we solving for?\n",
    "\n",
    "https://product-data-science.datamasked.com/courses/496549/lectures/9194606\n",
    "\n",
    "* Control = 66% @ £39\n",
    "* Variant = 33% @ £59\n",
    "* Experiment is running for 'some time'; outstanding questions: \n",
    "\n",
    "\n",
    "1. Should the product be sold @ £39 or £59? \n",
    "2. The VP of Product is interested in having a holistic view into user behavior, especially focusing on actionable insights that might increase conversion rate. What are your main findings looking at the data?\n",
    "\n",
    "\n",
    "3. The VP of Product feels that the test has been running for too long and they should have been able to get statistically significant results in a shorter time. Do you agree with this? After how many days you would have stopped the test? Please, explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:26.703374Z",
     "start_time": "2020-08-04T15:20:25.979859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annadudek/00_DataMasked\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import datetime\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from termcolor import colored \n",
    "import matplotlib as plt \n",
    "import seaborn as sns \n",
    "\n",
    "wd=os.getcwd()\n",
    "print(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:27.201342Z",
     "start_time": "2020-08-04T15:20:26.705503Z"
    }
   },
   "outputs": [],
   "source": [
    "events_raw = pd.read_csv(wd + '/06_pricing_test_results.csv')\n",
    "users_raw = pd.read_csv(wd + '/06_pricing_user_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:27.208446Z",
     "start_time": "2020-08-04T15:20:27.203204Z"
    }
   },
   "outputs": [],
   "source": [
    "def describe_data(data):\n",
    "    print(f\"shape: {data.shape}\")\n",
    "    print('')\n",
    "    print(data.dtypes)\n",
    "\n",
    "    \n",
    "    ## assume first id column in the dataset (in terms of left to right order)\n",
    "    try:\n",
    "        id_column=data.filter(like='id').columns.to_list()[0]\n",
    "        print('')\n",
    "        print(f\"Column taken as id: {id_column}\")\n",
    "        print(f\"If {len(data)} = {len(data[id_column].unique())}, then dataframe is at this level\") \n",
    "\n",
    "    except:\n",
    "        print(colored('No id column','red', attrs=['bold']))\n",
    "\n",
    "    \n",
    "    print('')\n",
    "    return data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:27.240744Z",
     "start_time": "2020-08-04T15:20:27.212112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (316800, 8)\n",
      "\n",
      "user_id              int64\n",
      "timestamp           object\n",
      "source              object\n",
      "device              object\n",
      "operative_system    object\n",
      "test                 int64\n",
      "price                int64\n",
      "converted            int64\n",
      "dtype: object\n",
      "\n",
      "Column taken as id: user_id\n",
      "If 316800 = 316800, then dataframe is at this level\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>device</th>\n",
       "      <th>operative_system</th>\n",
       "      <th>test</th>\n",
       "      <th>price</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604839</td>\n",
       "      <td>2015-05-08 03:38:34</td>\n",
       "      <td>ads_facebook</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624057</td>\n",
       "      <td>2015-05-10 21:08:46</td>\n",
       "      <td>seo-google</td>\n",
       "      <td>mobile</td>\n",
       "      <td>android</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317970</td>\n",
       "      <td>2015-04-04 15:01:23</td>\n",
       "      <td>ads-bing</td>\n",
       "      <td>mobile</td>\n",
       "      <td>android</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id            timestamp        source  device operative_system  test  \\\n",
       "0   604839  2015-05-08 03:38:34  ads_facebook  mobile              iOS     0   \n",
       "1   624057  2015-05-10 21:08:46    seo-google  mobile          android     0   \n",
       "2   317970  2015-04-04 15:01:23      ads-bing  mobile          android     0   \n",
       "\n",
       "   price  converted  \n",
       "0     39          0  \n",
       "1     39          0  \n",
       "2     39          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_data(events_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:27.288974Z",
     "start_time": "2020-08-04T15:20:27.267022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (275616, 5)\n",
      "\n",
      "user_id      int64\n",
      "city        object\n",
      "country     object\n",
      "lat        float64\n",
      "long       float64\n",
      "dtype: object\n",
      "\n",
      "Column taken as id: user_id\n",
      "If 275616 = 275616, then dataframe is at this level\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510335</td>\n",
       "      <td>Peabody</td>\n",
       "      <td>USA</td>\n",
       "      <td>42.53</td>\n",
       "      <td>-70.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89568</td>\n",
       "      <td>Reno</td>\n",
       "      <td>USA</td>\n",
       "      <td>39.54</td>\n",
       "      <td>-119.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>434134</td>\n",
       "      <td>Rialto</td>\n",
       "      <td>USA</td>\n",
       "      <td>34.11</td>\n",
       "      <td>-117.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     city country    lat    long\n",
       "0   510335  Peabody     USA  42.53  -70.97\n",
       "1    89568     Reno     USA  39.54 -119.82\n",
       "2   434134   Rialto     USA  34.11 -117.39"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_data(users_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:27.683168Z",
     "start_time": "2020-08-04T15:20:27.672371Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_dtypes(data): \n",
    "    \n",
    "    \"\"\" Transforms columns with 'date' or 'time' into date types. \n",
    "        Transforms any two-level columns into categories.\n",
    "        \n",
    "        USAGE: new_df = set_dtypes(example_df)\"\"\"\n",
    "\n",
    "    ### transforms dates \n",
    "    to_transform_dates=data.filter(like='date').columns.to_list()\n",
    "    if len(to_transform_dates) == 0:\n",
    "        print('no objects named date; trying time')\n",
    "        to_transform_dates=data.filter(like='time').columns.to_list()\n",
    "        for i in to_transform_dates:\n",
    "#             data[i] = pd.to_datetime(data[i])\n",
    "            data[['date','time']] = data[i].str.split(expand=True)\n",
    "            data['datetime'] = (pd.to_datetime(data.pop('date'), format='%Y-%m-%d') + \n",
    "                          pd.to_timedelta(data.pop('time')))\n",
    "    else: \n",
    "        for i in to_transform_dates:\n",
    "#             data[i] = pd.to_datetime(data[i])\n",
    "            data[['date','time']] = data[i].str.split(expand=True)\n",
    "            data['datetime'] = (pd.to_datetime(data.pop('date'), format='%Y-%m-%d') + \n",
    "                          pd.to_timedelta(data.pop('time')))\n",
    "    \n",
    "    print('')\n",
    "            \n",
    "     ### transforms numerics to binary      \n",
    "    to_transform_binary = data.select_dtypes('number').columns.tolist()\n",
    "    print(to_transform_binary)\n",
    "    binary_to_drop = input(\"Enter any columns that need omitting from binary transformation \")\n",
    "    binary_to_drop = list(binary_to_drop.split(' '))  \n",
    "    \n",
    "    try: \n",
    "        for x in binary_to_drop: \n",
    "            to_transform_binary.remove(x)\n",
    "    except: to_transform_binary\n",
    "        \n",
    "    print('')\n",
    "    for col in to_transform_binary:\n",
    "        if len(data[col].unique())>3:\n",
    "            to_transform_binary.remove(col)\n",
    "        else: \n",
    "            data[col] = data[col].astype('category')\n",
    "            \n",
    "            \n",
    "    print(data.dtypes)    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:33.464851Z",
     "start_time": "2020-08-04T15:20:28.033192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no objects named date; trying time\n",
      "\n",
      "['user_id', 'test', 'price', 'converted']\n",
      "Enter any columns that need omitting from binary transformation user_id price\n",
      "\n",
      "user_id                      int64\n",
      "timestamp                   object\n",
      "source                      object\n",
      "device                      object\n",
      "operative_system            object\n",
      "test                      category\n",
      "price                        int64\n",
      "converted                 category\n",
      "datetime            datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "events_raw = set_dtypes(events_raw)\n",
    "# events_raw['test'] = events_raw['test'].replace({0: 'control', 1: 'variant'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:33.604770Z",
     "start_time": "2020-08-04T15:20:33.467630Z"
    }
   },
   "outputs": [],
   "source": [
    "master_raw = pd.merge(events_raw, users_raw, how = 'left', on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:21:15.613074Z",
     "start_time": "2020-08-04T15:21:15.600844Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## transform to dates should always run first because all date-like objects will be considered an object \n",
    "## and will be made into dummies, which will unnecessarily explode the number of dummies \n",
    "\n",
    "def make_dummies(data): \n",
    "    \n",
    "    \"\"\" Takes all object columns and transforms them to dummy variables. Asks for input whether any variables\n",
    "        should be omitted. \n",
    "        \n",
    "        USAGE: new_df = make_dummies(example_df)\"\"\"\n",
    "    \n",
    "    dummies_list = []\n",
    "    variables=data.select_dtypes('object').columns.tolist()\n",
    "    print(\"number of unique values within object variables\")\n",
    "    for v in variables: \n",
    "        print(f\"{v}  {len(data[v].unique())}\")\n",
    "    \n",
    "    \n",
    "    print(variables)\n",
    "    variables_to_drop = input(\"Enter any columns that need omitting from becoming dummies \")\n",
    "    variables_to_drop = list(variables_to_drop.split(' '))  \n",
    "    \n",
    "    try: \n",
    "        for x in variables_to_drop: \n",
    "            variables.remove(x)\n",
    "    except: variabes\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    for var in variables:   \n",
    "        dummies_list = pd.get_dummies(data[var]).rename(columns=lambda x: str(var) + '_' + str(x))\n",
    "        data=data.join(dummies_list)\n",
    "#         del dummies_list\n",
    "    \n",
    "    return data    \n",
    "    \n",
    "\n",
    "\n",
    "def categorical_randomization(data, exp_group_col):\n",
    "    \n",
    "    \"\"\" Takes all the categorical variables in the dataframe and creates frequency tables by \n",
    "    Control v Variant in order to check randomization. \"\"\"\n",
    "    categorical_variables = data.select_dtypes('uint8').columns.tolist()   ## picks up on only dummied variables\n",
    "#     print(categorical_variables)\n",
    "#     columns_to_drop = input(\"Enter any columns that need omitting\")\n",
    "#     columns_to_drop = list(columns_to_drop.split(' '))  \n",
    "    \n",
    "#     try: \n",
    "#         for x in columns_to_drop: \n",
    "#             categorical_variables.remove(x)\n",
    "#     except: categorical_variables \n",
    "#     print('')\n",
    "              \n",
    "    \n",
    "    freq_table=pd.DataFrame()\n",
    "    for i in categorical_variables: \n",
    "        var_table=pd.DataFrame(data[[exp_group_col,i]].pivot_table(index=exp_group_col, columns=i, \n",
    "                                aggfunc=len, fill_value=0)).reset_index()\n",
    "#         print(var_table)\n",
    "\n",
    "        levels_list = var_table.columns.tolist()\n",
    "        levels_list.remove(exp_group_col)\n",
    "\n",
    "        for l in levels_list: \n",
    "            var_table[str(\"pct_\" + str(l))] = var_table[l]/var_table.sum(axis=1)\n",
    "        \n",
    "        freq_table = pd.concat([freq_table, var_table], axis =1)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \"\"\"Clean up freq_table & flag problematic randomization VARIANCE BETWEEN GROUPS > 5% \"\"\"\n",
    "    \n",
    "    freq_table=freq_table.transpose()\n",
    "    freq_table.reset_index(inplace=True)\n",
    "    freq_table.columns = ['categorical_variable', 'Control', 'Variant']\n",
    "    freq_table=freq_table[freq_table.categorical_variable != exp_group_col]\n",
    "    \n",
    "    freq_table['pct_variable']=freq_table['categorical_variable'].str.contains(\"pct\")\n",
    "    freq_table['group_variance'] = np.where(freq_table['pct_variable'] == True,\n",
    "                                            abs((freq_table['Control'] - freq_table['Variant'])/freq_table['Control']) , 0)\n",
    "\n",
    "\n",
    "    print(colored('Following categorical variables have greater than 5% variance between Control & Variant',\n",
    "                  'red', attrs=['bold']))\n",
    "    print(\"\")\n",
    "    print(freq_table[freq_table.group_variance >= 0.05])\n",
    "    \n",
    "    \n",
    "    pd.options.display.max_rows = 1000                              ## increase the length you can see in notebooks\n",
    "    return freq_table                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:20:47.563535Z",
     "start_time": "2020-08-04T15:20:41.532060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values within object variables\n",
      "timestamp  140931\n",
      "source  12\n",
      "device  2\n",
      "operative_system  6\n",
      "city  924\n",
      "country  2\n",
      "['timestamp', 'source', 'device', 'operative_system', 'city', 'country']\n",
      "Enter any columns that need omitting from becoming dummies timestamp city\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master_raw= make_dummies(master_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:21:18.000048Z",
     "start_time": "2020-08-04T15:21:17.174485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_ads-bing test       0      1\n",
      "0                  0  188118  14609\n",
      "1                  1  105809   8264\n",
      "[0, 1]\n",
      "source_ads-google test       0      1\n",
      "0                    0  164863  37864\n",
      "1                    1   92558  21515\n",
      "[0, 1]\n",
      "source_ads-yahoo test       0     1\n",
      "0                   0  197909  4818\n",
      "1                   1  111308  2765\n",
      "[0, 1]\n",
      "source_ads_facebook test       0      1\n",
      "0                      0  168628  34099\n",
      "1                      1   94776  19297\n",
      "[0, 1]\n",
      "source_ads_other test       0      1\n",
      "0                   0  183443  19284\n",
      "1                   1  103481  10592\n",
      "[0, 1]\n",
      "source_direct_traffic test       0      1\n",
      "0                        0  163968  38759\n",
      "1                        1   92475  21598\n",
      "[0, 1]\n",
      "source_friend_referral test       0      1\n",
      "0                         0  189592  13135\n",
      "1                         1  106513   7560\n",
      "[0, 1]\n",
      "source_seo-bing test       0     1\n",
      "0                  0  201393  1334\n",
      "1                  1  113254   819\n",
      "[0, 1]\n",
      "source_seo-google test       0      1\n",
      "0                    0  187625  15102\n",
      "1                    1  106000   8073\n",
      "[0, 1]\n",
      "source_seo-other test       0     1\n",
      "0                   0  196838  5889\n",
      "1                   1  110702  3371\n",
      "[0, 1]\n",
      "source_seo-yahoo test       0     1\n",
      "0                   0  198364  4363\n",
      "1                   1  111588  2485\n",
      "[0, 1]\n",
      "source_seo_facebook test       0      1\n",
      "0                      0  189256  13471\n",
      "1                      1  106339   7734\n",
      "[0, 1]\n",
      "device_mobile test      0       1\n",
      "0                0  82246  120481\n",
      "1                1  48083   65990\n",
      "[0, 1]\n",
      "device_web test       0      1\n",
      "0             0  120481  82246\n",
      "1             1   65990  48083\n",
      "[0, 1]\n",
      "operative_system_android test       0      1\n",
      "0                           0  154517  48210\n",
      "1                           1   87348  26725\n",
      "[0, 1]\n",
      "operative_system_iOS test       0      1\n",
      "0                       0  140872  61855\n",
      "1                       1   80463  33610\n",
      "[0, 1]\n",
      "operative_system_linux test       0     1\n",
      "0                         0  200520  2207\n",
      "1                         1  112145  1928\n",
      "[0, 1]\n",
      "operative_system_mac test       0      1\n",
      "0                       0  186361  16366\n",
      "1                       1  105354   8719\n",
      "[0, 1]\n",
      "operative_system_other test       0      1\n",
      "0                         0  192229  10498\n",
      "1                         1  108367   5706\n",
      "[0, 1]\n",
      "operative_system_windows test       0      1\n",
      "0                           0  139136  63591\n",
      "1                           1   76688  37385\n",
      "[0, 1]\n",
      "country_USA test      0       1\n",
      "0              0  26299  176428\n",
      "1              1  14885   99188\n",
      "[0, 1]\n",
      "\u001b[1m\u001b[31mFollowing categorical variables have greater than 5% variance between Control & Variant\u001b[0m\n",
      "\n",
      "   categorical_variable     Control     Variant pct_variable group_variance\n",
      "39                pct_1  0.00658025  0.00717949         True      0.0910668\n",
      "84                pct_1   0.0108865   0.0169012         True       0.552487\n",
      "89                pct_1   0.0807289   0.0764322         True      0.0532234\n"
     ]
    }
   ],
   "source": [
    "randomization_results=categorical_randomization(data= master_raw, exp_group_col = 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:13:38.250584Z",
     "start_time": "2020-08-04T15:13:38.240203Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_variables = master_raw.select_dtypes('uint8').columns.tolist()   ## picks up on only dummied variables\n",
    "categorical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:23:11.310052Z",
     "start_time": "2020-08-04T15:23:11.266864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>operative_system_other</th>\n",
       "      <th>test</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>pct_0</th>\n",
       "      <th>pct_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>192229</td>\n",
       "      <td>10498</td>\n",
       "      <td>0.948216</td>\n",
       "      <td>0.051784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108367</td>\n",
       "      <td>5706</td>\n",
       "      <td>0.949971</td>\n",
       "      <td>0.050020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "operative_system_other test       0      1     pct_0     pct_1\n",
       "0                         0  192229  10498  0.948216  0.051784\n",
       "1                         1  108367   5706  0.949971  0.050020"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_table = pd.DataFrame(master_raw[['test','operative_system_other']].pivot_table(index='test', columns='operative_system_other', \n",
    "                                aggfunc=len, fill_value=0)).reset_index()\n",
    "\n",
    "var_table[str(\"pct_\" + str(0))] = var_table[0]/var_table.sum(axis=1)\n",
    "var_table[str(\"pct_\" + str(1))] = var_table[1]/var_table.sum(axis=1)\n",
    "var_table        \n",
    "# freq_table = pd.concat([freq_table, var_table], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
