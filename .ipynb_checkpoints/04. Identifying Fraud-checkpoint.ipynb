{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Structure for all Notebooks \n",
    "\n",
    "## 1) Describe the problem being tackled, source of data, output \n",
    "## 2) Import libraries/set up wd; general working setup\n",
    "## 3) Examine the quality of the data \n",
    "## 4) Build the right dataset \n",
    "## 5) Apply the structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem \n",
    "### What are we solving for? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a ML model that predicts the probability that the first transaction of a new user is fraudulent.\n",
    "You only have information about the user first transaction on the site and based on that\n",
    "you have to make your classification\n",
    "\n",
    "* **I suppose you would be looking for whether the IP address is within the right bounds for a country.**\n",
    "\n",
    "For each user, determine their country based on the IP address\n",
    "\n",
    "\n",
    "Build a model to predict whether an activity is fraudulent or not. \n",
    "Explain how different assumptions about the cost of false positives vs false negatives would impact the model\n",
    "\n",
    "\n",
    "Your boss is a bit worried about using a model she doesn’t understand for something as important as fraud\n",
    "detection. How would you explain her how the model is making the predictions? Not from a mathematical perspective\n",
    "(she couldn’t care less about that), but from a user perspective. What kinds of users are more likely to be\n",
    "classified as at risk? What are their characteristics?\n",
    "\n",
    "\n",
    "Let’s say you now have this model which can be used live to predict in real time if an activity is fraudulent\n",
    "or not. From a product perspective, how would you use it? That is, what kind of different user experiences\n",
    "would you build based on the model output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T15:05:57.668339Z",
     "start_time": "2020-07-20T15:05:57.666060Z"
    }
   },
   "source": [
    "# Solution \n",
    "\n",
    "Random Forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:22:10.693695Z",
     "start_time": "2020-07-23T14:22:10.686079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annadudek/00_DataMasked\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "np.random.seed(4684)\n",
    "\n",
    "wd = os.getcwd()\n",
    "print(wd)\n",
    "\n",
    "## Solution: https://product-data-science.datamasked.com/courses/496549/lectures/9194598 \n",
    "## Github with Answers: https://github.com/JifuZhao/DS-Take-Home/blob/master/04.%20Identifying%20Fraudulent%20Activities.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:41:04.709336Z",
     "start_time": "2020-07-23T13:40:59.492599Z"
    }
   },
   "outputs": [],
   "source": [
    "txns_raw=pd.read_csv(\"https://drive.google.com/uc?export=download&id=18RLruiMU8rM-IQPLdwL6wNEc8Kks2JZQ\")\n",
    "ips_raw=pd.read_csv(\"https://drive.google.com/uc?export=download&id=1wbKys6YI-IvE-b-C0_4xR4zz2YnpOL1d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:37:52.501083Z",
     "start_time": "2020-07-23T14:37:52.496327Z"
    }
   },
   "outputs": [],
   "source": [
    "def describe_data(data):\n",
    "    print(f\" shape: {data.shape}\")\n",
    "    print('')\n",
    "    print(data.dtypes)\n",
    "\n",
    "    \n",
    "    ## assume first id column in the dataset (in terms of left to right order)\n",
    "    id_column = data.filter(like='id').columns.to_list()[0]\n",
    "    if len(id_column) != 0:\n",
    "        print('')\n",
    "        print(f\"Column taken as id: {id_column}\")\n",
    "        print(f\"If {len(data)} = {len(data[id_column].unique())}, then dataframe is at this level\")  \n",
    "    else:    \n",
    "        print('no id column')\n",
    "        print(colored('############  Accuracy Metrics  ############','blue', attrs=['bold']))\n",
    "    \n",
    "    print('')\n",
    "    return data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:38:21.913383Z",
     "start_time": "2020-07-23T14:38:21.908765Z"
    }
   },
   "outputs": [],
   "source": [
    "def describe_data(data):\n",
    "    print(f\" shape: {data.shape}\")\n",
    "    print('')\n",
    "    print(data.dtypes)\n",
    "\n",
    "    \n",
    "    ## assume first id column in the dataset (in terms of left to right order)\n",
    "    try:\n",
    "        id_column=data.filter(like='id').columns.to_list()[0]\n",
    "        print('')\n",
    "        print(f\"Column taken as id: {id_column}\")\n",
    "        print(f\"If {len(data)} = {len(data[id_column].unique())}, then dataframe is at this level\") \n",
    "\n",
    "    except:\n",
    "        print(colored('No id column','red', attrs=['bold']))\n",
    "\n",
    "    \n",
    "    print('')\n",
    "    return data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:36:55.630510Z",
     "start_time": "2020-07-23T14:36:55.604077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape: (151112, 17)\n",
      "\n",
      "user_id                         int64\n",
      "signup_time            datetime64[ns]\n",
      "purchase_time          datetime64[ns]\n",
      "purchase_value                  int64\n",
      "device_id                      object\n",
      "source                         object\n",
      "browser                        object\n",
      "sex                            object\n",
      "age                             int64\n",
      "ip_address                    float64\n",
      "class                           int64\n",
      "country                        object\n",
      "time_between                    int64\n",
      "same_day_purchase               int64\n",
      "time_between_binned            object\n",
      "signup_DOW                     object\n",
      "purchase_DOW                   object\n",
      "dtype: object\n",
      "\n",
      "Column taken as id: user_id\n",
      "If 151112 = 151112, then dataframe is at this level\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country</th>\n",
       "      <th>time_between</th>\n",
       "      <th>same_day_purchase</th>\n",
       "      <th>time_between_binned</th>\n",
       "      <th>signup_DOW</th>\n",
       "      <th>purchase_DOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>40-60 days</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id         signup_time       purchase_time  purchase_value  \\\n",
       "0    22058 2015-02-24 22:55:49 2015-04-18 02:47:11              34   \n",
       "1   333320 2015-06-07 20:39:50 2015-06-08 01:38:54              16   \n",
       "2     1359 2015-01-01 18:52:44 2015-01-01 18:52:45              15   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class        country  \\\n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0          Japan   \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  United States   \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  United States   \n",
       "\n",
       "   time_between  same_day_purchase time_between_binned signup_DOW purchase_DOW  \n",
       "0            52                  0          40-60 days    Tuesday     Saturday  \n",
       "1             0                  1                 NaN     Sunday       Monday  \n",
       "2             0                  1                 NaN   Thursday     Thursday  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_data(txns_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:38:23.566266Z",
     "start_time": "2020-07-23T14:38:23.557408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape: (138846, 3)\n",
      "\n",
      "lower_bound_ip_address    float64\n",
      "upper_bound_ip_address      int64\n",
      "country                    object\n",
      "dtype: object\n",
      "\u001b[1m\u001b[31mno id column\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower_bound_ip_address</th>\n",
       "      <th>upper_bound_ip_address</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16777216.0</td>\n",
       "      <td>16777471</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16777472.0</td>\n",
       "      <td>16777727</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16777728.0</td>\n",
       "      <td>16778239</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lower_bound_ip_address  upper_bound_ip_address    country\n",
       "0              16777216.0                16777471  Australia\n",
       "1              16777472.0                16777727      China\n",
       "2              16777728.0                16778239      China"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_data(ips_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:27:54.376247Z",
     "start_time": "2020-07-23T14:27:54.372126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416538"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe_data(ips_raw)\n",
    "ips_raw.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Country by IP Address "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:47.609246Z",
     "start_time": "2020-07-23T13:41:04.751280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United States        58049\n",
      "China                12038\n",
      "Japan                 7306\n",
      "United Kingdom        4490\n",
      "Korea Republic of     4162\n",
      "Germany               3646\n",
      "France                3161\n",
      "Canada                2975\n",
      "Brazil                2961\n",
      "Italy                 1944\n",
      "dtype: int64\n",
      "\n",
      " % of observations without a predicted country: 14.53623802212928\n"
     ]
    }
   ],
   "source": [
    "## creates a list of NoneTypes the length of the df  \n",
    "txns_raw_country = [None] * txns_raw.shape[0]\n",
    "   \n",
    "### For each entry in the txn_raws df, if the ip_address is greater than the lower bound ip address and less than the\n",
    "### higher bound up address then assign the countries for which it meets the conditions.\n",
    "## Then if there is only one country for which the row meets the conditions, input that country \n",
    "\n",
    "for i in range(txns_raw.shape[0]):\n",
    "    tmp = ips_raw[(txns_raw['ip_address'][i] >= ips_raw['lower_bound_ip_address']) & \n",
    "                          (txns_raw['ip_address'][i] <= ips_raw['upper_bound_ip_address'])]['country'].values\n",
    "    if (len(tmp) == 1):  \n",
    "        txns_raw_country[i] = tmp\n",
    "  \n",
    "\n",
    "### assigns the values to the dataframe and gets rid of the squared brackets \n",
    "txns_raw['country'] = txns_raw_country\n",
    "txns_raw['country'] = txns_raw['country'].str.get(0)\n",
    "\n",
    "## Results\n",
    "print(txns_raw.groupby('country').size().nlargest(10))\n",
    "print('')\n",
    "print(f\" % of observations without a predicted country: {(sum(txns_raw.country.isnull())/len(txns_raw.country))*100}\")\n",
    "\n",
    "txns_raw['country'].fillna(value='Unknown', inplace=True)\n",
    "\n",
    "\n",
    "#just keep the top 50 country, everything else is \"other\"; get countries from 51 to last one\n",
    "bottom_countries = txns_raw.groupby('country').size().sort_values(ascending=False)[50:].index\n",
    "x = dict.fromkeys(bottom_countries, 'Other')\n",
    "txns_raw['country'] = txns_raw['country'].replace(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Fraudulent Behaviour\n",
    "\n",
    "* Build a model to predict whether an activity is fraudulent or not. Explain how different assumptions about the cost of false positives vs false negatives would impact the model\n",
    "\n",
    "1. Create features \n",
    "2. Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:47.620378Z",
     "start_time": "2020-07-23T13:43:47.612286Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## transform to dates should always run first because all date-like objects will be considered an object \n",
    "## and will be made into dummies, which will unnecessarily explode the number of dummies \n",
    "\n",
    "def transform_to_dates(data):\n",
    "\n",
    "    to_transform_dates=data.filter(like='date').columns.to_list()\n",
    "    if len(to_transform_dates) == 0:\n",
    "        print('no objects named date; trying time')\n",
    "        to_transform_dates=data.filter(like='time').columns.to_list()\n",
    "        for i in to_transform_dates:\n",
    "            data[i] = pd.to_datetime(data[i])\n",
    "    else: \n",
    "        for i in to_transform_dates:\n",
    "            data[i] = pd.to_datetime(data[i])\n",
    "            \n",
    "    print(data.dtypes)    \n",
    "    return data\n",
    "\n",
    "def make_dummies(data): \n",
    "    dummies_list = []\n",
    "    variables=data.select_dtypes('object').columns.tolist()\n",
    "    print(variables)\n",
    "    \n",
    "    \n",
    "    for var in variables:   \n",
    "        dummies_list = pd.get_dummies(data[var]).rename(columns=lambda x: str(var) + '_' + str(x))\n",
    "        data=data.join(dummies_list)\n",
    "#         del dummies_list\n",
    "    \n",
    "    return data    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T13:43:48.899728Z",
     "start_time": "2020-07-23T13:43:47.623000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no objects named date; trying time\n",
      "user_id                    int64\n",
      "signup_time       datetime64[ns]\n",
      "purchase_time     datetime64[ns]\n",
      "purchase_value             int64\n",
      "device_id                 object\n",
      "source                    object\n",
      "browser                   object\n",
      "sex                       object\n",
      "age                        int64\n",
      "ip_address               float64\n",
      "class                      int64\n",
      "country                   object\n",
      "dtype: object\n",
      "['source', 'browser', 'sex', 'country', 'time_between_binned', 'signup_DOW', 'purchase_DOW']\n"
     ]
    }
   ],
   "source": [
    "## deal with dates // additional variables \n",
    "\n",
    "transform_to_dates(data = txns_raw)\n",
    "txns_raw['time_between']= (txns_raw['purchase_time']-txns_raw['signup_time']).dt.days\n",
    "txns_raw['same_day_purchase'] = np.where(txns_raw['time_between'] <=1, 1, 0)\n",
    "\n",
    "bins = [0, 20, 40, 60, 80, 100, 120]\n",
    "labels = ['0-20 days','20-40 days','40-60 days','60-80 days', '80-100 days', '100+ days', ]\n",
    "txns_raw['time_between_binned']=(pd.cut(txns_raw['time_between'], bins=bins, labels=labels)).astype(object)\n",
    "\n",
    "txns_raw['signup_DOW']=txns_raw['signup_time'].dt.day_name()\n",
    "txns_raw['purchase_DOW']=txns_raw['purchase_time'].dt.day_name()\n",
    "\n",
    "\n",
    "## make dummies \n",
    "txns_final=make_dummies(data = txns_raw[txns_raw.columns[txns_raw.columns!='device_id'] ])   ## want to omit device id as dummy\n",
    "txns_final=txns_final.join(txns_raw['device_id'])\n",
    "\n",
    "\n",
    "## additional features \n",
    "\n",
    "#check how for each device id, how many different users had it\n",
    "txns_final['device_id_count'] = txns_final.groupby('device_id')['device_id'].transform('count')\n",
    "txns_final['ip_address_count'] = txns_final.groupby('ip_address')['ip_address'].transform('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building - Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:09:14.713376Z",
     "start_time": "2020-07-23T14:09:14.603622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120889, 100)\n",
      "(30223, 100)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(txns_final, test_size=0.2, random_state=42)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "y_actual = 'class'\n",
    "\n",
    "\n",
    "variables_to_use = [\n",
    "#  'user_id',\n",
    "#  'signup_time',\n",
    "#  'purchase_time',\n",
    " 'purchase_value',\n",
    "#  'source',\n",
    "#  'browser',\n",
    "#  'sex',\n",
    "#  'age',\n",
    "#  'ip_address',\n",
    "#  'class',\n",
    "#  'country',\n",
    " 'time_between',\n",
    " 'same_day_purchase',\n",
    "#  'time_between_binned',\n",
    "#  'signup_DOW',\n",
    "#  'purchase_DOW',\n",
    " 'source_Ads',\n",
    " 'source_Direct',\n",
    " 'source_SEO',\n",
    " 'browser_Chrome',\n",
    " 'browser_FireFox',\n",
    " 'browser_IE',\n",
    " 'browser_Opera',\n",
    " 'browser_Safari',\n",
    " 'sex_F',\n",
    " 'sex_M',\n",
    " 'country_Argentina',\n",
    " 'country_Australia',\n",
    " 'country_Austria',\n",
    " 'country_Belgium',\n",
    " 'country_Brazil',\n",
    " 'country_Canada',\n",
    " 'country_Chile',\n",
    " 'country_China',\n",
    " 'country_Colombia',\n",
    " 'country_Czech Republic',\n",
    " 'country_Denmark',\n",
    " 'country_Egypt',\n",
    " 'country_European Union',\n",
    " 'country_Finland',\n",
    " 'country_France',\n",
    " 'country_Germany',\n",
    " 'country_Greece',\n",
    " 'country_Hong Kong',\n",
    " 'country_Hungary',\n",
    " 'country_India',\n",
    " 'country_Indonesia',\n",
    " 'country_Iran (ISLAMIC Republic Of)',\n",
    " 'country_Ireland',\n",
    " 'country_Israel',\n",
    " 'country_Italy',\n",
    " 'country_Japan',\n",
    " 'country_Korea Republic of',\n",
    " 'country_Malaysia',\n",
    " 'country_Mexico',\n",
    " 'country_Netherlands',\n",
    " 'country_New Zealand',\n",
    " 'country_Norway',\n",
    " 'country_Other',\n",
    " 'country_Poland',\n",
    " 'country_Portugal',\n",
    " 'country_Romania',\n",
    " 'country_Russian Federation',\n",
    " 'country_Saudi Arabia',\n",
    " 'country_South Africa',\n",
    " 'country_Spain',\n",
    " 'country_Sweden',\n",
    " 'country_Switzerland',\n",
    " 'country_Taiwan; Republic of China (ROC)',\n",
    " 'country_Thailand',\n",
    " 'country_Turkey',\n",
    " 'country_Ukraine',\n",
    " 'country_United Kingdom',\n",
    " 'country_United States',\n",
    " 'country_Unknown',\n",
    " 'country_Venezuela',\n",
    " 'country_Viet Nam',\n",
    " 'time_between_binned_0-20 days',\n",
    " 'time_between_binned_100+ days',\n",
    " 'time_between_binned_20-40 days',\n",
    " 'time_between_binned_40-60 days',\n",
    " 'time_between_binned_60-80 days',\n",
    " 'time_between_binned_80-100 days',\n",
    " 'signup_DOW_Friday',\n",
    " 'signup_DOW_Monday',\n",
    " 'signup_DOW_Saturday',\n",
    " 'signup_DOW_Sunday',\n",
    " 'signup_DOW_Thursday',\n",
    " 'signup_DOW_Tuesday',\n",
    " 'signup_DOW_Wednesday',\n",
    " 'purchase_DOW_Friday',\n",
    " 'purchase_DOW_Monday',\n",
    " 'purchase_DOW_Saturday',\n",
    " 'purchase_DOW_Sunday',\n",
    " 'purchase_DOW_Thursday',\n",
    " 'purchase_DOW_Tuesday',\n",
    " 'purchase_DOW_Wednesday',\n",
    "#  'device_id',\n",
    " 'device_id_count',\n",
    " 'ip_address_count'\n",
    "]\n",
    "\n",
    "# X = train[variables_to_use]\n",
    "# y = train['class']\n",
    "# z = test['class']\n",
    "\n",
    "X_train = train[variables_to_use]\n",
    "y_train = train[y_actual]\n",
    "\n",
    "X_test = test[variables_to_use]\n",
    "y_test = test[y_actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:09:31.856001Z",
     "start_time": "2020-07-23T14:09:16.056395Z"
    }
   },
   "outputs": [],
   "source": [
    "## Build model \n",
    "\n",
    "n = 6\n",
    "randoModel = RandomForestClassifier(n_estimators=100, max_features=n, oob_score=True)\n",
    "randoModel.fit(X_train,y_train)\n",
    "\n",
    "y_pred = randoModel.predict(X_test)\n",
    "test['y_hat']= randoModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:24:58.072135Z",
     "start_time": "2020-07-23T14:24:58.060490Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_forest_results(model): \n",
    "\n",
    "    print(colored('############  Accuracy Metrics  ############','blue', attrs=['bold']))\n",
    "    print('')\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print (\"Out of Bag Score:\", model.oob_score_)\n",
    "\n",
    "\n",
    "\n",
    "## which features are important \n",
    "    print('')\n",
    "    print(colored('############ Feature Importance  ############','blue', attrs=['bold']))\n",
    "    feature_imp = pd.Series(model.feature_importances_,\n",
    "                        index=variables_to_use).sort_values(ascending=False)\n",
    "    print('')\n",
    "    print('Feature Importance sorted - top n features: ')\n",
    "    print(feature_imp[0:n])\n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "## confusion matrix \n",
    "    print('')\n",
    "    print(colored('############ Confusion Matrix  ############','blue', attrs=['bold']))\n",
    "    confusion_matrix(test[y_actual], test['y_hat']) \n",
    "\n",
    "    df_confusion = pd.crosstab(test[y_actual], test['y_hat'],\n",
    "                           rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    print('')\n",
    "    print('confusion matrix - absolute values')\n",
    "    print(df_confusion)\n",
    "\n",
    "    print('')\n",
    "    print('confusion matrix - % values')\n",
    "    print(df_confusion / df_confusion.sum(axis=1))       ### represented as a percentage \n",
    "\n",
    "\n",
    "## Precision v Recall \n",
    "    print('')\n",
    "    print('############ Precision v Recall ############')\n",
    "    precision, recall, fscore, support = score(test[y_actual], test['y_hat'],labels=[0,1])\n",
    "\n",
    "\n",
    "## Precision: % of results that are TP of all the records identified positively. TP/(TP + FP) \n",
    "## Recall: % of results that are TP from all records that are TP and which were missed as TP (FN). TP/(TP + FN)\n",
    "## Accuracy: % of all positives and negatives identified correctly (TP + TN)/total records\n",
    "## F1-Score: \n",
    "## Support: \n",
    "\n",
    "\n",
    "    classification_report= pd.DataFrame(columns = ('metric', 'not_converted', 'converted'))\n",
    "\n",
    "    classification_report.loc[0] = ['precision', precision[0], precision[1]]\n",
    "    classification_report.loc[1] = ['recall', recall[0], recall[1]]\n",
    "    classification_report.loc[2] = ['fscore', fscore[0], fscore[1]]\n",
    "    classification_report.loc[3] = ['support', support[0], support[1]]\n",
    "\n",
    "    print(classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T14:24:59.666905Z",
     "start_time": "2020-07-23T14:24:59.557907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m############  Accuracy Metrics  ############\u001b[0m\n",
      "\n",
      "Accuracy: 0.9547033716044072\n",
      "Out of Bag Score: 0.9549504090529328\n",
      "\n",
      "\u001b[1m\u001b[34m############ Feature Importance  ############\u001b[0m\n",
      "\n",
      "Feature Importance sorted- top n features: \n",
      "time_between                      0.202308\n",
      "device_id_count                   0.151198\n",
      "ip_address_count                  0.146892\n",
      "purchase_value                    0.111399\n",
      "same_day_purchase                 0.096051\n",
      "time_between_binned_20-40 days    0.011431\n",
      "dtype: float64\n",
      "\n",
      "\u001b[1m\u001b[34m############ Confusion Matrix  ############\u001b[0m\n",
      "\n",
      "confusion matrix - absolute values\n",
      "Predicted      0     1    All\n",
      "Actual                       \n",
      "0          27310    63  27373\n",
      "1           1306  1544   2850\n",
      "All        28616  1607  30223\n",
      "\n",
      "confusion matrix - % values\n",
      "Predicted         0         1      All\n",
      "Actual                                \n",
      "0          0.498849  0.011053  0.45285\n",
      "1          0.023856  0.270877  0.04715\n",
      "All        0.522705  0.281930  0.50000\n",
      "\n",
      "############ Precision v Recall ############\n",
      "      metric  not_converted    converted\n",
      "0  precision       0.954361     0.960797\n",
      "1     recall       0.997698     0.541754\n",
      "2     fscore       0.975549     0.692843\n",
      "3    support   27373.000000  2850.000000\n"
     ]
    }
   ],
   "source": [
    "random_forest_results(model=randoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
